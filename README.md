# GPT-2-Text-Generator
Interactive Text Generation project using GPT-2 and ipywidgets
## ðŸ“¸ Preview

![Preview](preview.png)

An interactive notebook that uses Hugging Face's `distilgpt2` model to generate human-like text from user prompts. Built with clarity, modularity, and usability in mind â€” perfect for showcasing Generative AI capabilities.

## ðŸ” Project Overview

This project demonstrates text generation using a lightweight transformer model (`distilgpt2`) via Hugging Face. It features a clean UI with widgets for input, style control, and export functionality.

Created as part of the **Prodigy Infotech Generative AI internship**, it aligns with **Explainable AI** goals by offering structured outputs and user-driven customization.

## ðŸš€ How to Run

ðŸ‘‰ [Open in Google Colab](PASTE-YOUR-COLAB-LINK-HERE)

## Steps:
1. Click `Runtime > Run all`
2. Enter a prompt in the input field
3. Choose a tone/style (e.g. formal, casual)
4. Click "Generate Text"
5. ðŸ“¥ Press "Download Output" to save the result locally

## ðŸ“¦ Requirements

Install dependencies via:

```bash
pip install -r requirements.txt
